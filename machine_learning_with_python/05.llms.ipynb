{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5739ba48-5458-4877-b67d-935f0b276bac",
   "metadata": {},
   "source": [
    "# Large Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32a0917-927e-479f-891e-14a1644b5945",
   "metadata": {},
   "source": [
    "### Attention is all you need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72b6a6cc-f625-4448-96cb-249f7b9cab5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b110fb0-69ef-4085-af78-bc8ba988a371",
   "metadata": {},
   "source": [
    "Scaled Dot Product Attention$$\n",
    "\\text{Attention}(Q, K, V) = \\text{softmax}(\\frac{Q K^T}{\\sqrt{d_k}}) V\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f04724-7f71-447c-900a-336a3c63ac5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "500 x 512 512 x 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5d6d330-3553-4a86-af1f-3c60df3bd3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query: batch_size x n_heads x query_len x value_len\n",
    "# keys: batch_size x n_heads x query_len x value_len\n",
    "# value: batch_size x n_heads x query_len x value_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9ad0b76-934c-494f-aebb-73ee479c4a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, norm,dropout=0.1):\n",
    "        super(ScaledDotProductAttention, self).__init__()\n",
    "        self.norm = norm\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        scores = torch.matmul(query, key.transpose(-2,-1))\n",
    "        scores = scores / self.norm\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask==0, float('-inf'))\n",
    "        attention_probs = F.softmax(scores,dim=-1)\n",
    "        output = torch.matmul(self.dropout(attention_probs), value)\n",
    "        return output, attention_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1020ef0d-99c1-4616-a510-625437c11a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdp = ScaledDotProductAttention(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2eeb7741-fcef-4762-b01b-8991fc579134",
   "metadata": {},
   "outputs": [],
   "source": [
    "output, attns = sdp.forward(torch.randn((64,8,256,512)),torch.randn((64,8,256,512)),torch.randn((64,8,256,512)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5356e9fe-acef-41b5-88c0-85c4b0f62ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 8, 256, 512])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "679b9186-d625-42bb-a8e2-1fca54f259e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 8, 256, 256])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attns.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f9fc40-6490-4b44-8903-05081df7a5bd",
   "metadata": {},
   "source": [
    "Multihead Attention\n",
    "$$\\text{MultiHead}(Q, K, V) = \\text{Concat}(\\text{head}_1, \\dots, \\text{head}_h) W^O \\\\\n",
    "\\text{where}\\ \\text{head}_i = \\text{Attention}(QW_i^Q, KW_i^K, VW_i^V) \\\\\n",
    "W_i^Q \\in \\mathbb{R}^{\\mathrm{d_{model}\\times d_k}}, W_i^K \\in \\mathbb{R}^{\\mathrm{d_{model}\\times d_k}}, W_i^V \\in \\mathbb{R}^{\\mathrm{d_{model}\\times d_v}}, W_i^O \\in \\mathbb{R}^{\\mathrm{hd_v\\times d_{model}}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6ccf6a9b-5604-41ae-b435-0db4c0c65da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model, n_heads,dropout=0.1):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        assert d_model % n_heads == 0, \"`d_model` should be a multiple of `n_heads`\"\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.d_k = int(d_model / n_heads)\n",
    "\n",
    "        self.W_q = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.W_k = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.W_v = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.W_o = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.attention = ScaledDotProductAttention(np.sqrt(self.d_k))\n",
    "\n",
    "    def forward(self, q, k, v):\n",
    "        \"\"\"\n",
    "        q: batch_size x query_len x d_model\n",
    "        k: batch_size x query_len x d_model\n",
    "        v: batch_size x query_len x d_model\n",
    "        mask: batch_size x 1 x source_seq_len\n",
    "              batch_size x tgt_seq_len x tgt_seq_len\n",
    "        \"\"\"\n",
    "        print(q.size())\n",
    "\n",
    "        Q = q.view(q.size(0), -1, self.n_heads, self.d_k).transpose(1,2) # batch_size x n_heads x query_len x d_k\n",
    "        K = k.view(k.size(0), -1, self.n_heads, self.d_k).transpose(1,2)\n",
    "        V = v.view(v.size(0), -1, self.n_heads, self.d_k).transpose(1,2)\n",
    "\n",
    "        # calc attention\n",
    "        x, attn = self.attention(Q,K,V)\n",
    "\n",
    "        # regroup \n",
    "        x = x.transpose(1,2).contiguous().view(x.size(0), -1, self.n_heads * self.d_k)\n",
    "        x = self.W_o(x)\n",
    "\n",
    "        return x, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c9cb9fe4-993d-4b5f-b0a5-6ff3963acf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "mha = MultiHeadAttention(d_model=512,n_heads=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6c0a27d7-ec30-42f9-9ecd-a85a08720580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn((64,512,8,512)).size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cf075d58-524d-4abc-9815-7b639fd47564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size x query_len x d_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "60c0c715-155c-467d-a821-5cd274f974f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64.0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "512/8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "80f39c1e-035a-4a2e-b7ce-1b3bb87fee88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 256, 512])\n"
     ]
    }
   ],
   "source": [
    "output, attns = mha.forward(torch.randn((64,256,512)),torch.randn((64,256,512)),torch.randn((64,256,512)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e843998d-0bc2-4dd9-8381-9a430a0b12bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 256, 512])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1b1faa3a-3b39-4e25-9fc6-276d45621e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 8, 256, 256])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attns.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64477c5-e717-4122-9e11-1b2cde922d3a",
   "metadata": {},
   "source": [
    "$$\n",
    "FFN(x) = max(0, xW_1 + b_1)W_2 + b_2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3e127584-2be5-43a8-a39f-3640680e4ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionFeedForward(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, d_ff, dropout_rate=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_ff = d_ff\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        self.w1 = nn.Linear(d_model, d_ff)\n",
    "        self.w2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.dropout(F.relu(self.w_1(x)))\n",
    "        x = self.w_2(x)\n",
    "        return x\n",
    "        # batch_size, seq_len, d_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d43216d-f89b-49b4-8b05-95090d8d2a5f",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{PE}_{(pos, 2i)} &= \\text{sin}(\\frac{pos}{10000^{2i/d_{model}}}) \\\\\n",
    "\\text{PE}_{(pos, 2i + 1)} &= \\text{cos}(\\frac{pos}{10000^{2i/d_{model}}})\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9cb88d1a-3cba-4ff1-88ba-eb716bce6785",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout_rate=0.1,maxlen=10000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.maxlen = maxlen\n",
    "\n",
    "        pe = torch.zeros(maxlen, d_model)\n",
    "        position = torch.arange(0, maxlen).unsqueeze(1)\n",
    "\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model)\n",
    "        )  # (d_model,)\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        # make these static\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        x= self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9ca23dc9-47a5-4881-8ae7-83f7d0a1b66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout_rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.d_ff = d_ff\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        self.attention_layer = MultiHeadAttention(d_model, n_heads, dropout_rate)\n",
    "        self.attention_layer_norm = nn.LayerNorm(d_model, eps=1e-6)\n",
    "\n",
    "        self.ff_layer= PositionFeedForward(d_model, d_ff, dropout_rate)\n",
    "        self.ff_layer_norm = nn.LayerNorm(d_model, eps=1e-6)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "\n",
    "    def forward(self,x, mask):\n",
    "\n",
    "        x1 = self.attention_layer(x,x,x,mask)\n",
    "        x = self.attention_layer_norm(x+ self.dropout(x1))\n",
    "        x1= self.ff_layer(x)\n",
    "        x = self.ff_layer_norm(x+self.dropout(x1))\n",
    "\n",
    "        return x\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5bb94854-0b47-4d91-b844-742f022e6b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, d_model, n_layers, n_heads, d_ff, dropout_rate=0.1,maxlen=10000):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.d_model = d_model\n",
    "        self.n_layers = n_layers\n",
    "        self.n_heads = n_heads\n",
    "        self.d_ff = d_ff\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.maxlen = maxlen\n",
    "\n",
    "\n",
    "        self.tok_embedding = nn.Linear(vocab_size, d_model)\n",
    "        self.pos_embedding = PositionalEncoding(d_model, dropout_rate=dropout_rate,maxlen=maxlen)\n",
    "        self.layers = nn.ModuleList([\n",
    "            EncoderLayer(d_model, n_heads, d_ff, dropout_rate)\n",
    "            for _ in range(n_layers)\n",
    "        ])\n",
    "        self.layer_norm = nn.LayerNorm(d_model, dropout_rate=dropout_rate)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        # x : batch_size x seq_len\n",
    "        x = self.tok_embedding(x)\n",
    "        x = self.pos_embedding(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        x = self.layer_norm(x)\n",
    "        return x\n",
    "        # batch_size x seq_len x d_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c5fb4336-df81-4be1-b7e2-a1d1cbdfd0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout_rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.d_ff = d_ff\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        self.attn_layer = MultiHeadAttention(d_model, n_heads, dropout_rate)\n",
    "        self.attn_layer_norm = nn.LayerNorm(d_model, eps=1e-6)\n",
    "\n",
    "        self.ff_layer = PositionwiseFeedForward(d_model, d_ff, dropout_rate)\n",
    "        self.ff_layer_norm = nn.LayerNorm(d_model, eps=1e-6)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.encoder_attn_layer = MultiHeadAttention(d_model, n_heads, dropout_rate)\n",
    "        self.encoder_attn_layer_norm = nn.LayerNorm(d_model, eps=1e-6)\n",
    "\n",
    "    def forward(self, x, encoder_op, src_mask, tgt_mask):\n",
    "\n",
    "        x1 = self.attn_layer(x,x,x,tgt_mask)\n",
    "        x = self.attn_layer_norm(x + self.dropout(x1))\n",
    "        x1, attn = self.encoder_attn_layer(x, encoder_op, encoder_op, src_mask)\n",
    "        x = self.encoder_attn_layer(x+self.dropout(x1))\n",
    "\n",
    "        x1 = self.ff_layer(x)\n",
    "        x = self.ff_layer_norm(x+nn.Dropout(x1))\n",
    "\n",
    "        return x, attn   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8e10b4d3-3229-4089-9387-fdde53c183dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, d_model, n_layers, n_heads, d_ff, dropout_rate=0.1,maxlen=10000):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.d_model = d_model\n",
    "        self.n_layers = n_layers\n",
    "        self.n_heads = n_heads\n",
    "        self.d_ff = d_ff\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.maxlen = maxlen\n",
    "\n",
    "\n",
    "        self.tok_embedding = nn.Linear(vocab_size, d_model)\n",
    "        self.pos_embedding = PositionalEncoding(d_model, dropout_rate=dropout_rate,maxlen=maxlen)\n",
    "        self.layers = nn.ModuleList([\n",
    "            DecoderLayer(d_model, n_heads, d_ff, dropout_rate)\n",
    "            for _ in range(n_layers)\n",
    "        ])\n",
    "        self.layer_norm = nn.LayerNorm(d_model, dropout_rate=dropout_rate)\n",
    "\n",
    "    def forward(self, x, enc_output, src_mask, tgt_mask):\n",
    "        # x : batch_size x seq_len\n",
    "        x = self.tok_embedding(x)\n",
    "        x = self.pos_embedding(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, encodermask)\n",
    "        x = self.layer_norm(x, enc_output, src_mask, tgt_mask)\n",
    "        return x\n",
    "        # batch_size x seq_len x d_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "57411bb3-e1ee-410e-bb5f-bfc8190495eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoder, decoder, linear_mapper):\n",
    "\n",
    "        self.encoder= encoder\n",
    "        self.decoder= decoder\n",
    "        self.linear_mapper = linear_mapper\n",
    "\n",
    "    def forward(self,src,tgt):\n",
    "        enc_output = self.encoder(src)\n",
    "        dec_output, attn = self.decoder(tgt, enc_output)\n",
    "        output = self.linear_mapper(dec_output)\n",
    "        return output, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "90c4fd1f-4b36-4ed8-b37b-2ee75e5339de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearMapper(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model, vocab_size):\n",
    "        super(LinearMapper, self).__init__()\n",
    "        self.affine_map = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.affine_map(x) \n",
    "        output = F.log_softmax(x, dim=-1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7262f118-d503-4fa4-b9ec-978f579b9d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = nn.Transformer(d_model=512, nhead=8, \n",
    "                             num_encoder_layers=6, num_decoder_layers=6, \n",
    "                             dim_feedforward=2048, dropout=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9b1c7ca2-39aa-4d47-a7b5-27146159a5aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder): TransformerDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d884053-a1a4-4ffd-b515-9f8c43cf7ec4",
   "metadata": {},
   "source": [
    "### Finetuning Decoder Only Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "a64cf0b5-ebdc-46b7-a3a5-7029e22f47d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import normalizers\n",
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"SuryaKrishna02/aya-telugu-poems\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "495bab3b-a738-41ce-a217-24e75a26fde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(x):\n",
    "    for each_s in x:\n",
    "        yield each_s['inputs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "2a6331aa-9339-440e-9f9b-6aa3a5eb44c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = generate_data(ds['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "9316fad1-4a1f-46f6-9728-0aa801a70323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer, models, pre_tokenizers, decoders, trainers, processors\n",
    "\n",
    "tokenizer = Tokenizer(models.BPE())\n",
    "\n",
    "tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()\n",
    "\n",
    "trainer = trainers.BpeTrainer(vocab_size=1000, special_tokens=[\"<s>\", \"<pad>\", \"</s>\", \"<unk>\"])\n",
    "\n",
    "tokenizer.train_from_iterator(g, trainer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "482a8066-fdff-43f3-9d87-c5236e695625",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, embed_size, max_len):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, embed_size, 2) * (-math.log(10000.0) / embed_size))\n",
    "        pe = torch.zeros(max_len, 1, embed_size)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.pe = pe\n",
    "\n",
    "    def forward(self, x):\n",
    "        # batch, len, d_model\n",
    "        seq_len = x.size(1)\n",
    "        x = x + self.pe[:x.size(0), :, :].to(x.device)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240652ec-4372-47e1-a1e3-03a21a719769",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "d996e965-48b9-4317-a969-684712725802",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class DecoderOnlyTransformer(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, d_model, n_layers, n_heads, d_ff, \n",
    "                 dropout_rate=0.1,max_len=32):\n",
    "        \n",
    "        super(DecoderOnlyTransformer, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.d_model = d_model\n",
    "        self.n_layers = n_layers\n",
    "        self.n_heads = n_heads\n",
    "        self.d_ff = d_ff\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.max_len = max_len\n",
    "\n",
    "        self.position_embedding = PositionalEncoding(d_model, max_len)\n",
    "        self.tok_embedding = nn.Embedding(vocab_size, d_model)\n",
    "        decoder_layer = nn.TransformerDecoderLayer(d_model=embed_size, \n",
    "                                                   nhead =n_heads, \n",
    "                                                   dim_feedforward=d_ff)\n",
    "        self.transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers=n_layers)\n",
    "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.tok_embedding(x)\n",
    "        x = self.position_embedding(x)\n",
    "        x = self.transformer_decoder(x,memory=x)\n",
    "        logits = self.fc_out(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "7f76c898-0048-4837-a25d-c0f61f003d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "embed_size = 512  \n",
    "num_heads = 8  \n",
    "num_layers = 6 \n",
    "hidden_dim = 2048  \n",
    "max_len = 32 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "037b48b5-486f-440b-8385-878bf85f0544",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = generate_data(ds['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "d5b157d3-7654-4690-848d-7305f18fed36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data(corpus, tokenizer, max_len=32):\n",
    "    tokenized_corpus = [tokenizer.encode(sentence).ids for sentence in corpus]\n",
    "    tokenized_corpus = [x[0:max_len] for x in tokenized_corpus]\n",
    "    return tokenized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "6adb6780-2125-4ef8-a60b-99849e205d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_corpus = tokenize_data(g, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "075815b2-d973-4e2c-a210-d4da7b8a79c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5115"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "309a8404-76d2-4631-905d-f0454f445fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "sequence_length = 32\n",
    "input_sequences = torch.zeros((batch_size, sequence_length), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "ba784c62-f71d-462e-a6d9-fbf6bf3948a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 32])"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "a54c8079-e0b2-4edb-a8f2-33997c75a0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(batch_size):\n",
    "    input_sequences[i, :len(tokenized_corpus[i])] = torch.tensor(tokenized_corpus[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "a41b789f-1b6d-42af-8270-5e19ac6c3b17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 32])"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "22a0fecc-b266-4e9c-ba67-6be386acd118",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = DecoderOnlyTransformer( vocab_size=30000, d_model=512, n_layers=6, n_heads=8, \n",
    "                       d_ff=512, dropout_rate=0.1,max_len=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "8fb7f43d-0540-47b8-98bd-4f504145a576",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "177a9af7-c97d-401a-9761-3340f9f6e5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 10.540102005004883\n",
      "Epoch 2/10, Loss: 8.720990180969238\n",
      "Epoch 3/10, Loss: 7.641439437866211\n",
      "Epoch 4/10, Loss: 6.5575408935546875\n",
      "Epoch 5/10, Loss: 5.865268230438232\n",
      "Epoch 6/10, Loss: 5.230606555938721\n",
      "Epoch 7/10, Loss: 4.630501747131348\n",
      "Epoch 8/10, Loss: 4.067417144775391\n",
      "Epoch 9/10, Loss: 3.589400053024292\n",
      "Epoch 10/10, Loss: 3.262800455093384\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    transformer.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    logits = transformer(input_sequences)\n",
    "    \n",
    "    # Shift input by 1 token to compute next token prediction loss\n",
    "    target_sequences = input_sequences[:, 1:]\n",
    "    logits = logits[:, :-1, :].reshape(-1, 30000)  # Reshape for loss computation\n",
    "    target_sequences = target_sequences.reshape(-1)\n",
    "    \n",
    "    # Compute loss\n",
    "    loss = criterion(logits, target_sequences)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4414136-5ad1-4b86-a4e8-e3783041e7f0",
   "metadata": {},
   "source": [
    "### Lora Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "2018113d-c61b-4293-a277-74ff726c1af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sandeep/anaconda3/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "# Load pre-trained GPT-2 model and tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "77d98a3b-54c7-443a-8fa6-69325517ff7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,  \n",
    "    lora_alpha=32,  \n",
    "    target_modules=[\"c_attn\"],  \n",
    "    lora_dropout=0.1, \n",
    "    bias=\"none\",  #\n",
    "    task_type=\"CAUSAL_LM\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "eb2a272d-5923-4621-948e-384dbe26df03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sandeep/anaconda3/lib/python3.12/site-packages/peft/tuners/lora/layer.py:1091: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "80485ba1-6f35-489f-98e1-595ef6315569",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load a dataset (e.g., WikiText)\n",
    "dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")\n",
    "\n",
    "# Tokenize the dataset\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], return_tensors=\"pt\", padding=True, truncation=True,max_length=512)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "b3e7d78e-cd14-47ef-8d5d-8f4a788986db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da355048e8614d238f2f93b2668352df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4358 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f6c4e420fa947808b5f0657753c02cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/36718 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4c47602647742219c810fb9e9b3b9e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3760 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_and_prepare_labels(examples):\n",
    "    # Tokenize the input text\n",
    "    tokenized_inputs = tokenizer(examples['text'], return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    \n",
    "    # GPT-2 uses the input as the label, so we clone the input_ids\n",
    "    tokenized_inputs[\"labels\"] = tokenized_inputs[\"input_ids\"].clone()\n",
    "\n",
    "    return tokenized_inputs\n",
    "\n",
    "# Apply the tokenization and labeling function\n",
    "tokenized_dataset = dataset.map(tokenize_and_prepare_labels, batched=True, remove_columns='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "89f8f5d1-fa08-4d52-9b2b-35b7d996aa02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "473"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_dataset['train'][1]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "1a44adb4-f55d-48c5-a8b3-4c1fc557c36a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 36718\n",
       "})"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "bbb424ad-964d-4e21-bc7d-a3d81ef72b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sandeep/anaconda3/lib/python3.12/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='110154' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [    41/110154 27:49 < 1309:11:46, 0.02 it/s, Epoch 0.00/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>8.289100</td>\n",
       "      <td>9.181212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>8.096900</td>\n",
       "      <td>8.818974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>7.296600</td>\n",
       "      <td>8.414536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='375' max='3760' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 375/3760 00:39 < 05:58, 9.44 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[472], line 26\u001b[0m\n\u001b[1;32m     18\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     19\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     20\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m     21\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtokenized_dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     22\u001b[0m     eval_dataset\u001b[38;5;241m=\u001b[39mtokenized_dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     23\u001b[0m )\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Fine-tune the model\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/transformers/trainer.py:1938\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1936\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1937\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1938\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1939\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1940\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1943\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/transformers/trainer.py:2356\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2353\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m epoch \u001b[38;5;241m+\u001b[39m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m steps_skipped) \u001b[38;5;241m/\u001b[39m steps_in_epoch\n\u001b[1;32m   2354\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 2356\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2357\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2358\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_substep_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/transformers/trainer.py:2804\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2802\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2803\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_evaluate:\n\u001b[0;32m-> 2804\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2806\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[1;32m   2807\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_checkpoint(model, trial, metrics\u001b[38;5;241m=\u001b[39mmetrics)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/transformers/trainer.py:2761\u001b[0m, in \u001b[0;36mTrainer._evaluate\u001b[0;34m(self, trial, ignore_keys_for_eval, skip_scheduler)\u001b[0m\n\u001b[1;32m   2760\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_evaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, ignore_keys_for_eval, skip_scheduler\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m-> 2761\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2762\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step, metrics)\n\u001b[1;32m   2764\u001b[0m     \u001b[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/transformers/trainer.py:3666\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3663\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3665\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 3666\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3667\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3668\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3669\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   3670\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   3671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3674\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3676\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   3677\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/transformers/trainer.py:3847\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3844\u001b[0m observed_num_examples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3846\u001b[0m \u001b[38;5;66;03m# Main evaluation loop\u001b[39;00m\n\u001b[0;32m-> 3847\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   3848\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Update the observed num examples\u001b[39;49;00m\n\u001b[1;32m   3849\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfind_batch_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3850\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/accelerate/data_loader.py:559\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;66;03m# But we still move it to the device so it is done before `StopIteration` is reached\u001b[39;00m\n\u001b[1;32m    558\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 559\u001b[0m         current_batch \u001b[38;5;241m=\u001b[39m \u001b[43msend_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_non_blocking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_state_dict()\n\u001b[1;32m    561\u001b[0m     next_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(dataloader_iter)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/accelerate/utils/operations.py:185\u001b[0m, in \u001b[0;36msend_to_device\u001b[0;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m skip_keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    182\u001b[0m         skip_keys \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensor)(\n\u001b[1;32m    184\u001b[0m         {\n\u001b[0;32m--> 185\u001b[0m             k: t \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m skip_keys \u001b[38;5;28;01melse\u001b[39;00m \u001b[43msend_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m k, t \u001b[38;5;129;01min\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    187\u001b[0m         }\n\u001b[1;32m    188\u001b[0m     )\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/accelerate/utils/operations.py:156\u001b[0m, in \u001b[0;36msend_to_device\u001b[0;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[1;32m    154\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxpu:0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# .to() doesn't accept non_blocking as kwarg\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",  \n",
    "    num_train_epochs=3,  \n",
    "    logging_dir=\"./logs\",  \n",
    "    logging_steps=10,  \n",
    "    save_steps=500, \n",
    "    learning_rate=5e-5,  \n",
    "    evaluation_strategy=\"steps\", \n",
    "    save_total_limit=2,\n",
    "    per_device_train_batch_size =1,\n",
    "    per_device_eval_batch_size =1\n",
    ")\n",
    "\n",
    "# Initialize the trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    ")\n",
    "\n",
    "# Fine-tune the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c32f4f-3457-47dd-89bb-a7ed83ab2912",
   "metadata": {},
   "source": [
    "### LLama Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1334a233-14af-4c60-be1e-59a8f28163bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

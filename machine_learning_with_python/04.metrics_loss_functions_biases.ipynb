{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60f775c8-4c13-4bfe-bd04-b94a2da2f2d0",
   "metadata": {},
   "source": [
    "# Metrics and Biases\n",
    "\n",
    "#### Biases in ML systems\n",
    "\n",
    "##### Data Biases\n",
    "\n",
    "* Sampling bias: Data mismatch with the real distribution\n",
    "    * Training a model on data that is convenient for you or ready for you potentially excluding other cases.\n",
    "* Labelling bias: Inaccurate or inconsistent labels\n",
    "* Historical bias: Data collected in the past may not be representative\n",
    "* Recency bias: The recent data might not be representative.\n",
    "\n",
    "##### Model Biases\n",
    "\n",
    "* Confirmation Bias: Model could be biased towards existing beliefs\n",
    "* Overfitting: Model too faithful to the data it was trained on\n",
    "* Feature Bias: Gender, Race, Zipcodes could be correlated and lead to biased models\n",
    "* Algorithmic Bias: Algorithms could inherently be biased towards a class or view\n",
    "    * Decision Trees priortize higher information gain. It could lead to unfair predictions that target specific groups.\n",
    "    * Adverserial Attacks: Neural Networks can be prone to attacks where the model could be mislead by carefully modifying the input.\n",
    "    * Recommender Systems: Can cause filter bubbles where all users will be recommended similar items because of the underlying data already has biases.\n",
    "    * Word Embeddings can be misleading as the text could be having a lot of biases. Certain professions may be correlated to certain genders. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c328bf-005d-4d3d-90cf-6e6c7a991f96",
   "metadata": {},
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2260bb1a-e15b-4a8c-a760-bbbf71978c88",
   "metadata": {},
   "source": [
    "##### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa3a42f-caa1-4fa3-b89d-c5b6fd4fbf9f",
   "metadata": {},
   "source": [
    "                  Predicted Class\n",
    "                  +---------------+---------------+--------------+\n",
    "                  |               |  Positive     |  Negative    |\n",
    "                  +---------------+---------------+--------------+\n",
    "    Actual Class  |  Positive     |  TP (True     |   FN (False  |\n",
    "                  |               |  Positive)    |  Negative)   |\n",
    "                  +---------------+---------------+--------------+\n",
    "                  |  Negative     |  FP (False    |  TN (True    |\n",
    "                  |               |  Positive)    |  Negative)   |\n",
    "                  +---------------+---------------+--------------+\n",
    "\n",
    "\n",
    "                  Predicted Class\n",
    "                  +---------------+---------------+------------------+\n",
    "                  |               |  Positive      |  Negative       |\n",
    "                  +---------------+---------------+------------------+\n",
    "    Actual Class  |  Positive     |  (TP)          |   (FN)          |\n",
    "                  |               |  (Sensitivity) |  (Type-2 Error) |\n",
    "                  +---------------+---------------+------------------+\n",
    "                  |  Negative     |  (FP)          |      (TN)       |\n",
    "                  |               |(Type-1 Error)  |  (Specificity)  |\n",
    "                  +---------------+---------------+------------------+"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a5806f-5598-4cb1-9e0d-60d1c2396667",
   "metadata": {},
   "source": [
    "* Accuracy: (TP+TN) / (TP+FP+FN+TN)\n",
    "* Precision: TP / (TP+FP)\n",
    "* Recall: TP / (TP+FN)\n",
    "* f1-score: 2 * Precision * Recall / (Precision+Recall)\n",
    "* Sensitivity=Recall\n",
    "* Specificity: True negatives among all negatives = TN/(TN+FP)\n",
    "* ROC: Graph at various thresholds between True Positive Rate (y-axis) vs False Positive Rate (x-axis):\n",
    "    * TPR = Sensitivity = Recall\n",
    "    * FPR: FP + TN = 1 =>\n",
    "        * FPR = 1- TN or 1 - Specificity\n",
    "        * FPR= 1 - (TN/TN+FP) = FP / (TN+FP)\n",
    "* ROC Curves are threshold-invariant.\n",
    "* AUC: Area under curve from ROC\n",
    "* Log Loss: Cross entropy loss\n",
    "$$ L(y, \\hat{y}) = -\\sum_{i=1}^n y_i \\log(\\hat{y}_i) + (1-y_i) \\log(1-\\hat{y}_i) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54bc226c-93bf-44e4-8d08-af5578cd840c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21ec6977-263b-4a2a-b4ff-1b0730d7e975",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(y_true, y_pred, threshold=0.5):\n",
    "    y_pred = np.where(y_pred >= 0.5, 1, 0)\n",
    "    mat = np.zeros((2,2))\n",
    "    tp = mat[0,0] = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    tn = mat[1,1] = np.sum((y_true == 0) & (y_pred == 0))\n",
    "    fp = mat[1,0] = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    fn = mat[0,1] = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1b7f69a-b8ec-43ce-9117-0de26601eee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 1.],\n",
       "       [1., 1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(np.array([0,1,0,1,1]),np.array([0.3,0.9,0.9,0.6,0.4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6e819b-b0e1-4b6d-9a8e-123a4222af55",
   "metadata": {},
   "source": [
    "#### Imbalanced datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c692fe-0cda-4053-8699-4d3e30863687",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3916a22-41e9-4040-bf67-19c48774100a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "348ac6df-bad8-4426-bfec-41feb7231064",
   "metadata": {},
   "source": [
    "#### Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bbc336-24ec-49f1-91b0-5de59ab580d0",
   "metadata": {},
   "source": [
    "* Mean Squared Error\n",
    "* R*2 score\n",
    "* Mean Absolute Error\n",
    "* Mean Absolute Percentage Error\n",
    "* Explained Variance Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af2abfba-cb4f-4ccc-9899-815501e5c147",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_true, y_pred):\n",
    "    return np.mean((y_true-y_pred)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c98147cf-ee09-4d92-b064-cf2e8469ded0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(y_true, y_pred):\n",
    "    return np.mean(np.abs(y_true-y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0794cd25-79ac-423b-bc22-43acc46a5d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(y_true, y_pred):\n",
    "    return np.mean(np.abs(y_true-y_pred) / y_true) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92a80990-7800-4266-a863-d372d575cb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_score(y_true, y_pred):\n",
    "    sse = np.sum((y_true-y_pred) ** 2)\n",
    "    sst = np.sum((y_true-np.mean(y_true)) ** 2)\n",
    "    return 1 - sse/ sst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ca18f2-b9fb-49d5-9668-e87771974de7",
   "metadata": {},
   "source": [
    "#### Retrieval / Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48433c44-f4a8-4adf-8cf2-a9b58868348e",
   "metadata": {},
   "source": [
    "* Precision@ k: Number of Relevant Docs / Number of Retrieved docs @k\n",
    "* Recall @ k: Number of Relevant Docs @ k/ Total number of Relevant docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb1b21b8-15cd-41c9-aca4-4d6a661f56bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(relevant_docs, retrieved_docs,k):\n",
    "    relevant_in_topk = len(set(relevant_docs).intersection(retrieved_docs[:k]))\n",
    "    return relevant_in_topk / k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f61fe2db-aa1f-4ea2-bbec-f5249b610626",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_at_k(relevant_docs, retrieved_docs,k):\n",
    "    relevant_in_topk = len(set(relevant_docs).intersection(retrieved_docs[:k]))\n",
    "    return relevant_in_topk / len(relevant_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d38427e-0a0d-4035-b5b7-06d8fb67644d",
   "metadata": {},
   "source": [
    "* Mean average Precision: Averages the precision at every position in the ranking where a relevant document appears\n",
    "$$    MAP = \\frac{1}{N} \\sum_{i=1}^{N} \\left( \\frac{1}{|R_i|} \\sum_{k=1}^{|R_i|} P(k) \\right) $$\n",
    "\n",
    "    * Predicted ranking: [D1, D2, D3, D4, D5], documents are assumed to be ranked according to scores\n",
    "    * Relevance labels: [1,0,1,1,1]\n",
    "    * At Position 1: Precision = 1/1 = 1\n",
    "    * Position 2: Precision = 0 (document 2 not relevant)\n",
    "    * Position 3: Precision = 2/3\n",
    "    * Position 4: 3/4\n",
    "    * Position 5: 4/5\n",
    "    * Mean average precision = 1/4 x (1+2/3+3/4+4/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0ef779d-4848-466c-90bc-7f94a0d23847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_precision(y_true, y_pred):\n",
    "    relevant = 0\n",
    "    precisions = []\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_true[i] == 1:\n",
    "            # relevant, compute\n",
    "            relevant += 1\n",
    "            precision_at_i = relevant / (i+1)\n",
    "            precisions.append(precision_at_i)\n",
    "    return np.sum(precisions) / len(precisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "944cc471-2d03-4eed-b422-12e6924150c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8041666666666667"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_precision([1,0,1,1,1],[1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab66f677-32bb-49b3-85f6-87e451a6f564",
   "metadata": {},
   "source": [
    "* NDCG (Normalized Discounted Cumulative Gain)\n",
    "    * Considers the position of the document in the retrieved list\n",
    "     $$ DCG_k = \\sum_{i=1}^{k} \\frac{\\text{rel}_i}{\\log_2(i + 1)} $$\n",
    "    * At position 1 => 1/ log2 = 1\n",
    "    * Position 2 = 1/ log(3)\n",
    "    * Position 3 = 1/log(4) = .5\n",
    "    * As the position increases, the weightage on the metric decreases\n",
    "    * NDCG normalizes DCG by considering ideal rank.\n",
    "    $$    nDCG_k = \\frac{DCG_k}{IDCG_k} $$\n",
    "    * Ground Truth = [3, 2, 3, 0, 1]\n",
    "    * Predicted Scores = [2, 3, 3, 1, 0]\n",
    "    * DCG = 2 / log(1+1) + 3 / log(2+1) + 3/ log(3+1) + 1 / log(4+1) + 0/log(5+1)\n",
    "    * Ideal DCG: Ideal Rank = [3,3,2,1,0]\n",
    "    * IDCG = 3 / log(1+1) + 3 / log(2+1) + 2/ log(3+1) + 1 / log(4+1) + 0/log(5+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e58978c6-a9f4-46a4-8434-72492c424415",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg_at_k(relevance_scores , k):\n",
    "    top_k_scores = relevance_scores[:k]\n",
    "    denominator = np.log(np.arange(2,2+k))\n",
    "    return np.sum(top_k_scores/ denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a9c8fa27-cd83-41ea-b49b-d2077bc1d1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndcg_at_k(y_true, y_pred, k):\n",
    "    y_true_sorted = np.sort(y_true)\n",
    "    idcg = dcg_at_k(y_true_sorted,k)\n",
    "    order = np.argsort(y_pred)[::-1]\n",
    "    y_true = np.take(y_true, order)\n",
    "    dcg = dcg_at_k(y_true,k)\n",
    "    return dcg / idcg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8744781c-7938-42a4-b53e-1cce2694fb5a",
   "metadata": {},
   "source": [
    "* Mean Resiprocal Rank (MRR)\n",
    "  $$ MRR = \\frac{1}{N} \\sum_{i=1}^{N} \\frac{1}{\\text{rank}_i} $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80538be9-4949-4749-9d5f-81c34e970c21",
   "metadata": {},
   "source": [
    "#### LLM Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2cb567-0b38-4ccb-a630-a4b13dcd45a9",
   "metadata": {},
   "source": [
    "* Evaluating quality of generative text models\n",
    "    * Perplexity: How well model predicts a sample of the test dataset. Lower perplexity indicates better performance.\n",
    "$$ PP = \\exp \\left( -\\frac{1}{n} \\sum_{i=1}^{n} \\log p(x_i) \\right) $$\n",
    "$$ L = -\\frac{1}{n} \\sum_{i=1}^{n} \\sum_{k=1}^{K} y_{ik} \\log p(x_i = k) $$\n",
    "    * BLEU (Bilingual Evaluation Understudy Score): Measures overlap between generated text and reference text.\n",
    "$$ BS = \\exp \\left( \\sum_{n=1}^{4} w_n \\log p_n \\right) $$\n",
    "        * Calculate precision for each n-gram\n",
    "        * Original: \"Quick brown fox\".\n",
    "        * Generated: \"Quick browns fox\".\n",
    "        * P@1: 2/3, P@2: 1/3, P@3: 0/3\n",
    "        * BLEU = exp(w1 * log(p@1) + w2 * log(p@2) + w3 * log(p@3))\n",
    "    * ROUGE (Recall-Oriented Understudy for Gisting Evaluation)\n",
    "$$ RS = \\frac{1}{n} \\sum_{i=1}^{n} \\frac{\\sum_{k=1}^{K} \\min (count_{ik}, count_{ik}')}{\\sum_{k=1}^{K} count_{ik}'} $$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
